# -*- coding: utf-8 -*-
"""InseptionV3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/179XPOGUdv7urlCX-i-VTAH3JByQDSj06
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from skimage.metrics import structural_similarity as ssim

start_model = InceptionV3(weights = 'imagenet', include_top = False)

for layer in start_model.layers:
  layer.trainable  = False

x = start_model.output
# start_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='sigmoid')(x)
predictions = Dense(141, activation='softmax')(x)

model = Model(inputs=start_model.input, outputs=predictions)

model.compile(optimizer="adam", loss='categorical_crossentropy', metrics=['accuracy'])

train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    validation_split=0.2
    )

train_data_dir = '/content/drive/MyDrive/Datasets/1'
img_width, img_height = 299, 299
batch_size = 128

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True)

validation_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation')

with tf.device('GPU'):
  model.fit(
      train_generator,
      steps_per_epoch=train_generator.samples // batch_size,
      epochs=12,
      validation_data=validation_generator,
      validation_steps=validation_generator.samples // batch_size,
      verbose=1)

model.save('fine_tuned_inceptionv3.h5')

model.save('/content/drive/MyDrive/InceptionV3')

from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

import os

def predict_image(image_path, model, classes):

    # Load and preprocess the image
    img = load_img(image_path, target_size=(299, 299))
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    # Make prediction
    prediction = model.predict(img_array)

    # Decode prediction
    max_index = np.argmax(prediction)
    predicted_class = classes[max_index]
    confidence = prediction[0][max_index]

    # Return class label and confidence score
    return predicted_class, confidence

# Example usage
image_path = "/content/drive/MyDrive/Datasets/1/0/n01443537_135.JPEG"
folder_path = "/content/drive/MyDrive/Datasets/1"
classes = os.listdir(folder_path)
predicted_class, confidence = predict_image(image_path, model, classes)
print("Predicted class:", predicted_class)
print("Confidence:", confidence)

import os
import cv2
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim

def calculate_ssim(reference_image, image_folder, num_top_images=3):
    # Load the reference image
    ref_img = cv2.imread(reference_image, cv2.IMREAD_GRAYSCALE)
    if ref_img is None:
        print("Error: Reference image not found or could not be loaded.")
        return

    # Load the input image without modification
    input_img = cv2.imread(reference_image, cv2.IMREAD_COLOR)
    if input_img is None:
        print("Error: Input image not found or could not be loaded.")
        return

    # Initialize dictionary to store SSIM scores and corresponding filenames
    ssim_scores = {}

    # Iterate through all files in the folder
    for filename in os.listdir(image_folder):
        # Check if the file is an image
        img_path = os.path.join(image_folder, filename)
        if os.path.isfile(img_path):
            # Load the image
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                print(f"Error: Image '{filename}' not found or could not be loaded.")
                continue

            # Calculate SSIM
            score = ssim(ref_img, img)

            # Store SSIM score with filename
            ssim_scores[filename] = score

    # Sort SSIM scores in descending order
    sorted_ssim_scores = sorted(ssim_scores.items(), key=lambda x: x[1], reverse=True)

    # Display the reference image
    plt.figure()
    plt.imshow(cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB))
    plt.title("Input Image")
    plt.axis('off')
    plt.show()

    for i, (filename, score) in enumerate(sorted_ssim_scores[:num_top_images]):

        img_path = os.path.join(image_folder, filename)
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.figure()
        plt.imshow(img_rgb)
        plt.title(f"Top {i+1} HIGHEST : (SSIM: {score:.2f})")
        plt.axis('off')
        plt.show()

        print("The path: ", os.path.join(image_folder,filename))


image_folder = f"/content/drive/MyDrive/Datasets/1/{predicted_class}"
calculate_ssim(image_path, image_folder)